{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Installing necessary dependencies\n",
    "import sys\n",
    "# !conda install --yes --prefix {sys.prefix} PIL\n",
    "# # !{sys.executable} -m pip install ____\n",
    "\n",
    "\n",
    "# !{sys.executable} -m pip install pytesseract\n",
    "# !{sys.executable} -m pip install pillow\n",
    "# !{sys.executable} -m pip install python-poppler\n",
    "# !{sys.executable} -m pip install opencv-python\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !conda install -c conda-forge poppler\n",
    "\n",
    "# !{sys.executable} -m pip install scipy\n",
    "# !{sys.executable} -m pip install sklearn\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install nltk\n",
    "# !{sys.executable} -m pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "# import pandas as pd\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "# import numpy as np\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FUnction to extract words from a pdf and save it in as a text file\n",
    "\n",
    "def pdf_2_txt(path):          \n",
    "    for file in os.listdir(path): # goes through the folders'\n",
    "        if file.endswith('.pdf'): # finds pdfs\n",
    "            p = os.path.join(path,file) # grabs path of pdf\n",
    "            pdfpages = convert_from_path(p, 500) # Converting each page in the pdf into image file with 500 dpi\n",
    "            image_counter = 1\n",
    "            for page in pdfpages:\n",
    "                filename = f\"page_{image_counter}.jpg\"\n",
    "                # Save the image of the page in system\n",
    "                page.save(filename, 'JPEG')\n",
    "                image_counter+=1\n",
    "                text = str(((pytesseract.image_to_string(Image.open(filename))))) # takes image and process into text\n",
    "                # delete image\n",
    "                os.remove(filename)\n",
    "                text = text.replace('-\\n', '') # some text processing\n",
    "                                \n",
    "                # Checking if the page contains the \"Course objective or \n",
    "                # description or outline or goals or Learning Outcomes followed by an \"end of string\" and\n",
    "                # a new line (As a title)\"\n",
    "                \n",
    "                if re.match(re.compile(\"^Course\\s(Outline|Objectives|Objective|Description|Goals)$\\n\"),\n",
    "                            text) or re.match(re.compile(\"^Learing Outcomes$\\n\"), text):\n",
    "                    filename = filename.replace('.jpg','') # Naming\n",
    "                    with open(f'{filename}.txt', 'w+') as f: # Opens a text file and writes the characters onto\n",
    "                        print(text, file=f)\n",
    "                        print(f'Page_{image_counter}.txt has been saved into {os.getcwd()}')\n",
    "                    break # stops iteration as soon as page is found               \n",
    "                \n",
    "    return #text\n",
    "                    \n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page_3.txt has been saved into C:\\Users\\15713\\Desktop\n"
     ]
    }
   ],
   "source": [
    "# Implementing pdf to image conversion\n",
    "path = os.getcwd()\n",
    "pdf_2_txt(path)\n",
    "# pages = convert_from_path(path, 500) \n",
    "# for page in pages:\n",
    "#     page.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, I try to do some text processing and tokenization to see word frequencies\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from __future__ import division\n",
    "import matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\15713\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') # downloads all stopwords to avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we have several .txt files of the same pdf, then we use this function to combine into 1 text file (not saved)\n",
    "def combine_pages(path):\n",
    "    # Combining pages\n",
    "    pages = ''\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.txt'):\n",
    "            with codecs.open(file, 'r') as f: \n",
    "                page = f.read()\n",
    "                pages+=page\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a list of unecessary words like 'the', 'or',... to avoid\n",
    "avoid = stopwords.words('english')\n",
    "avoid.append('edu') # adding our own word to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize a text file into sentences or phrases\n",
    "def get_sentence_counter(path=None, text=None):\n",
    "    if path:\n",
    "        path = os.getcwd()\n",
    "        for file in os.listdir():\n",
    "            if file.endswith('.txt'):\n",
    "                with codecs.open(file, 'r') as f: \n",
    "                    text = f.read()\n",
    "    else:\n",
    "        text = text\n",
    "    # groups all words and white-spaces, then finds words until a punctuation is reached\n",
    "    regex_of_sentence = re.findall('([\\w\\s]{0,})[^\\w\\s]', text) \n",
    "    avoid = re.findall('\\d', text)\n",
    "    avoid.append('')\n",
    "    regex_of_sentence = [x for x in regex_of_sentence if x not in avoid]\n",
    "    # for i in regex_of_sentence:\n",
    "    #     print(i)\n",
    "    return collections.Counter(regex_of_sentence), len(regex_of_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize a text file into words\n",
    "def get_text_counter(text, avoid, word_pattern):\n",
    "#     tokens = WordPunctTokenizer().tokenize(PorterStemmer().stem(text))\n",
    "    tokens = WordPunctTokenizer().tokenize(text)\n",
    "    tokens = list(map(lambda x: x.lower(), tokens)) # converting everything to lower-case\n",
    "    # cleaning up tokens by getting rid of stopwords and finding word characters\n",
    "    Puncs = [token for token in tokens if re.match(re.compile(\"\\W\"), token)] # finding all punctuations\n",
    "    Nums = [token for token in tokens if re.match(re.compile(\"\\d\"), token)] # finding all digit characters\n",
    "    # adding punctuations and digits to the list of avoided characters/words\n",
    "    avoid = Puncs + Nums\n",
    "    tokens = [token for token in tokens if re.match(word_pattern, token) and token not in avoid] \n",
    "    # collections.counter() returns the tokens and their frequency as a dictionary ({freq: token})\n",
    "    return collections.Counter(tokens), len(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make dataframe for both tokenized words and sentences with their abs and relative freqz\n",
    "def make_df(counter, size, ind_name):\n",
    "    abs_freq = np.array([x[1] for x in counter]) # the absolute freqz is found from the collections.counter()\n",
    "    rel_freq = abs_freq/size # relative freqz is calculated by dividing abs_freqz by the size\n",
    "    index = [x[0] for x in counter] # the tokens are used as an index \n",
    "    # creating the dataframe\n",
    "    df = pd.DataFrame(data=np.array([abs_freq, rel_freq]).T, \n",
    "                      index=index,\n",
    "                      columns=[\"Absolute frequency\",\"Relative frequency\"])\n",
    "    # Naming the index title\n",
    "    df.index.name = ind_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Least Commonly\n",
       " Occuring Sentences</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Your grade will be determined by your participation in discussions and submitted\\nreviews</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You will be a reviewer or reader for 4 grants and participate in a simulated NIH\\nstudy section</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n\\nAssignment</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSF and NIH pdfs and web sites</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Writing and Reviewing Research Proposals\\nReading</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n\\n6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiz on Leedy Ch 11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leedy Ch11 and completion of the Linked In course on R\\n\\nEvaluation</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantitative Analyses and Review of Statistical Procedures\\nReading</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7\\n\\n5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiz on Leedy Ch 4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perk\\nEvaluation</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>editors</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elsevier</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Publication Ethics from Elsevier web site\\n\\nhttps</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sections of Leedy Ch 4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\nReading</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research Ethics</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confounding Variables</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sources of Bias</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\nSampling</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimental Design</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantitative and Qualitative Research</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Research Process</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n\\n4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List and discuss Strengths and Weaknesses of the Writing</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s suggestions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>according to the Baylor Sections and identify where the paper corresponds and where it\\ndoes not to Baylor</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from your Literature\\nReview</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class presentation of an analysis of one paper</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Bates and 3 Borja pdfs</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Writing a Manuscript for Publication\\nReading</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n\\n3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS\\ntopic due in 4 weeks</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on your PhD</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 references</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 pages</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Literature review report</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skim Leedy Ch3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n\\nReading</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by Chris Magee</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n\\nTraining on Reference Manager Software Zotero</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by Theresa Calcagno</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How to Do a Literature Review\\n\\nTraining on Library databases for literature searches</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2\\n\\n2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiz on Leedy Chapters</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in class</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdfs</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Absolute frequency  \\\n",
       "Least Commonly\\n Occuring Sentences                                      \n",
       " Your grade will be determined by your particip...                 1.0   \n",
       " You will be a reviewer or reader for 4 grants ...                 1.0   \n",
       "\\n\\nAssignment                                                     1.0   \n",
       " NSF and NIH pdfs and web sites                                    1.0   \n",
       " Writing and Reviewing Research Proposals\\nRead...                 1.0   \n",
       "\\n\\n6                                                              1.0   \n",
       " quiz on Leedy Ch 11                                               1.0   \n",
       " Leedy Ch11 and completion of the Linked In cou...                 1.0   \n",
       " Quantitative Analyses and Review of Statistica...                 1.0   \n",
       "7\\n\\n5                                                             1.0   \n",
       " quiz on Leedy Ch 4                                                1.0   \n",
       "perk\\nEvaluation                                                   1.0   \n",
       "editors                                                            1.0   \n",
       "com                                                                1.0   \n",
       "elsevier                                                           1.0   \n",
       "www                                                                1.0   \n",
       " Publication Ethics from Elsevier web site\\n\\nh...                 1.0   \n",
       " Sections of Leedy Ch 4                                            1.0   \n",
       "\\nReading                                                          1.0   \n",
       " Research Ethics                                                   1.0   \n",
       " Confounding Variables                                             1.0   \n",
       " Sources of Bias                                                   1.0   \n",
       "\\nSampling                                                         1.0   \n",
       " Experimental Design                                               1.0   \n",
       " Quantitative and Qualitative Research                             1.0   \n",
       " The Research Process                                              1.0   \n",
       "\\n\\n4                                                              1.0   \n",
       " List and discuss Strengths and Weaknesses of t...                 1.0   \n",
       "s suggestions                                                      1.0   \n",
       " according to the Baylor Sections and identify ...                 1.0   \n",
       "from your Literature\\nReview                                       1.0   \n",
       " Class presentation of an analysis of one paper                    1.0   \n",
       " 4 Bates and 3 Borja pdfs                                          1.0   \n",
       " Writing a Manuscript for Publication\\nReading                     1.0   \n",
       "\\n\\n3                                                              1.0   \n",
       "MS\\ntopic due in 4 weeks                                           1.0   \n",
       " on your PhD                                                       1.0   \n",
       " 25 references                                                     1.0   \n",
       "5 pages                                                            1.0   \n",
       " Literature review report                                          1.0   \n",
       " Skim Leedy Ch3                                                    1.0   \n",
       "\\n\\nReading                                                        1.0   \n",
       "by Chris Magee                                                     1.0   \n",
       "\\n\\nTraining on Reference Manager Software Zotero                  1.0   \n",
       "by Theresa Calcagno                                                1.0   \n",
       " How to Do a Literature Review\\n\\nTraining on L...                 1.0   \n",
       " 2\\n\\n2                                                            1.0   \n",
       " quiz on Leedy Chapters                                            1.0   \n",
       " in class                                                          1.0   \n",
       "pdfs                                                               1.0   \n",
       "\n",
       "                                                    Relative frequency  \n",
       "Least Commonly\\n Occuring Sentences                                     \n",
       " Your grade will be determined by your particip...            0.011494  \n",
       " You will be a reviewer or reader for 4 grants ...            0.011494  \n",
       "\\n\\nAssignment                                                0.011494  \n",
       " NSF and NIH pdfs and web sites                               0.011494  \n",
       " Writing and Reviewing Research Proposals\\nRead...            0.011494  \n",
       "\\n\\n6                                                         0.011494  \n",
       " quiz on Leedy Ch 11                                          0.011494  \n",
       " Leedy Ch11 and completion of the Linked In cou...            0.011494  \n",
       " Quantitative Analyses and Review of Statistica...            0.011494  \n",
       "7\\n\\n5                                                        0.011494  \n",
       " quiz on Leedy Ch 4                                           0.011494  \n",
       "perk\\nEvaluation                                              0.011494  \n",
       "editors                                                       0.011494  \n",
       "com                                                           0.011494  \n",
       "elsevier                                                      0.011494  \n",
       "www                                                           0.011494  \n",
       " Publication Ethics from Elsevier web site\\n\\nh...            0.011494  \n",
       " Sections of Leedy Ch 4                                       0.011494  \n",
       "\\nReading                                                     0.011494  \n",
       " Research Ethics                                              0.011494  \n",
       " Confounding Variables                                        0.011494  \n",
       " Sources of Bias                                              0.011494  \n",
       "\\nSampling                                                    0.011494  \n",
       " Experimental Design                                          0.011494  \n",
       " Quantitative and Qualitative Research                        0.011494  \n",
       " The Research Process                                         0.011494  \n",
       "\\n\\n4                                                         0.011494  \n",
       " List and discuss Strengths and Weaknesses of t...            0.011494  \n",
       "s suggestions                                                 0.011494  \n",
       " according to the Baylor Sections and identify ...            0.011494  \n",
       "from your Literature\\nReview                                  0.011494  \n",
       " Class presentation of an analysis of one paper               0.011494  \n",
       " 4 Bates and 3 Borja pdfs                                     0.011494  \n",
       " Writing a Manuscript for Publication\\nReading                0.011494  \n",
       "\\n\\n3                                                         0.011494  \n",
       "MS\\ntopic due in 4 weeks                                      0.011494  \n",
       " on your PhD                                                  0.011494  \n",
       " 25 references                                                0.011494  \n",
       "5 pages                                                       0.011494  \n",
       " Literature review report                                     0.011494  \n",
       " Skim Leedy Ch3                                               0.011494  \n",
       "\\n\\nReading                                                   0.011494  \n",
       "by Chris Magee                                                0.011494  \n",
       "\\n\\nTraining on Reference Manager Software Zotero             0.011494  \n",
       "by Theresa Calcagno                                           0.011494  \n",
       " How to Do a Literature Review\\n\\nTraining on L...            0.011494  \n",
       " 2\\n\\n2                                                       0.011494  \n",
       " quiz on Leedy Chapters                                       0.011494  \n",
       " in class                                                     0.011494  \n",
       "pdfs                                                          0.011494  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing functions for sentences or phrases\n",
    "path = os.getcwd()\n",
    "sentence_count, size = get_sentence_counter(path)\n",
    "df_sentence = make_df(sentence_count.most_common()[:-n-1:-1], size,\n",
    "             ind_name='Least Commonly\\n Occuring Sentences') # finds the least commonly occuring sentences\n",
    "df_sentence.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Least Commonly\n",
       " Occuring Words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proposal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submitted</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discussions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participation</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>determined</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulated</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grants</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reader</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewer</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sites</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewing</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linked</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completion</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ch11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>procedures</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyses</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perk</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>editors</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confounding</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sources</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experimental</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualitative</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaknesses</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strengths</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggestions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>does</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corresponds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identify</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Absolute frequency  Relative frequency\n",
       "Least Commonly\\n Occuring Words                                        \n",
       "proposal                                        1.0            0.002985\n",
       "page                                            1.0            0.002985\n",
       "submit                                          1.0            0.002985\n",
       "reviews                                         1.0            0.002985\n",
       "submitted                                       1.0            0.002985\n",
       "discussions                                     1.0            0.002985\n",
       "participation                                   1.0            0.002985\n",
       "determined                                      1.0            0.002985\n",
       "grade                                           1.0            0.002985\n",
       "section                                         1.0            0.002985\n",
       "study                                           1.0            0.002985\n",
       "simulated                                       1.0            0.002985\n",
       "participate                                     1.0            0.002985\n",
       "grants                                          1.0            0.002985\n",
       "reader                                          1.0            0.002985\n",
       "or                                              1.0            0.002985\n",
       "reviewer                                        1.0            0.002985\n",
       "sites                                           1.0            0.002985\n",
       "reviewing                                       1.0            0.002985\n",
       "r                                               1.0            0.002985\n",
       "linked                                          1.0            0.002985\n",
       "completion                                      1.0            0.002985\n",
       "ch11                                            1.0            0.002985\n",
       "procedures                                      1.0            0.002985\n",
       "statistical                                     1.0            0.002985\n",
       "analyses                                        1.0            0.002985\n",
       "perk                                            1.0            0.002985\n",
       "editors                                         1.0            0.002985\n",
       "com                                             1.0            0.002985\n",
       "www                                             1.0            0.002985\n",
       "https                                           1.0            0.002985\n",
       "site                                            1.0            0.002985\n",
       "variables                                       1.0            0.002985\n",
       "confounding                                     1.0            0.002985\n",
       "bias                                            1.0            0.002985\n",
       "sources                                         1.0            0.002985\n",
       "sampling                                        1.0            0.002985\n",
       "design                                          1.0            0.002985\n",
       "experimental                                    1.0            0.002985\n",
       "qualitative                                     1.0            0.002985\n",
       "weaknesses                                      1.0            0.002985\n",
       "strengths                                       1.0            0.002985\n",
       "list                                            1.0            0.002985\n",
       "suggestions                                     1.0            0.002985\n",
       "s                                               1.0            0.002985\n",
       "not                                             1.0            0.002985\n",
       "does                                            1.0            0.002985\n",
       "it                                              1.0            0.002985\n",
       "corresponds                                     1.0            0.002985\n",
       "identify                                        1.0            0.002985"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing functions for sentences or phrases\n",
    "path = os.getcwd()\n",
    "pages = combine_pages(path) # combining every text file in folder\n",
    "word_count, size = get_text_counter(pages, avoid, word_pattern) # returns tokens freqz and count of tokens\n",
    "n = 1000 # 1000 of least commonly occuring words\n",
    "# least commonly occuring words are chosen with the assumption that a syllabus will only mention\n",
    "# technical terms once or twice while other words like 'students' and so on could be redundant\n",
    "df_word = make_df(word_count.most_common()[:-n-1:-1], size,\n",
    "             ind_name='Least Commonly\\n Occuring Words') # finds the least commonly occuring words\n",
    "df_word.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just showing a complete list of the words tokenized\n",
    "# uncomment if you want to try\n",
    "# n = 1000\n",
    "# print([x[0] for x in word_count.most_common()[:-n-1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just showing a complete list of the words tokenized\n",
    "# uncomment if you want to try\n",
    "# n = 1000\n",
    "# print([x[0] for x in sentence_count.most_common()[:-n-1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with 'Indeed Dataset'\n",
    "path = os.path.join(os.getcwd(), 'indeed_dataset.csv')\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Links</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Software Engineer Security and Authenti...</td>\n",
       "      <td>MathWorks</td>\n",
       "      <td>Natick, MA 01760</td>\n",
       "      <td>https://indeed.com/viewjob?jk=dedaae73a1bb2555</td>\n",
       "      <td>None</td>\n",
       "      <td>We are looking for a highly motivated work-fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Citizens</td>\n",
       "      <td>Greenville, RI 02828</td>\n",
       "      <td>https://indeed.com/viewjob?jk=8b0ad10599f3a304</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Description:\\nAre you looking for a new an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021745 Cyber Security Analysts $215,000.00</td>\n",
       "      <td>B4CORP</td>\n",
       "      <td>Reston, VA</td>\n",
       "      <td>https://indeed.com/viewjob?jk=407b2677aa6ccc25</td>\n",
       "      <td>Up to $215,000 a year</td>\n",
       "      <td>US CITIZENSHIP REQUIRED FOR THIS POSITION: Yes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Cyber Security Analyst</td>\n",
       "      <td>TherapyNotes.com</td>\n",
       "      <td>Remote</td>\n",
       "      <td>https://indeed.com/viewjob?jk=0dd5712bac6c57aa</td>\n",
       "      <td>None</td>\n",
       "      <td>Cyber Security Analyst, Incident Response, Cyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyber Security Analyst</td>\n",
       "      <td>NDK</td>\n",
       "      <td>Morrisville, NC•Remote</td>\n",
       "      <td>https://indeed.com/viewjob?jk=2d39ed3a3baf0863</td>\n",
       "      <td>Up to $130,000 a year</td>\n",
       "      <td>Information Security Engineer\\nThe Information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>CentralSquare Technologies</td>\n",
       "      <td>+1 locationRemote</td>\n",
       "      <td>https://indeed.com/viewjob?jk=56f081f9afeb537e</td>\n",
       "      <td>$85,000 - $100,000 a year</td>\n",
       "      <td>This role leads initiatives in risk, product s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cyber Security Engineer</td>\n",
       "      <td>Softnice Inc.</td>\n",
       "      <td>Remote</td>\n",
       "      <td>https://indeed.com/viewjob?jk=8b05a98ec7ae4b42</td>\n",
       "      <td>None</td>\n",
       "      <td>Job description:\\nStrong IT skills and knowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>https://indeed.com/viewjob?jk=5025373d360ec8f3</td>\n",
       "      <td>None</td>\n",
       "      <td>Bachelor’s degree in Computer Science, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cyber Security and Networking Apprentice</td>\n",
       "      <td>United States Navy Career Center South Bay</td>\n",
       "      <td>Redwood City, CA+2 locations</td>\n",
       "      <td>https://indeed.com/viewjob?jk=77b578b9c0642d23</td>\n",
       "      <td>$50,000 - $95,000 a year</td>\n",
       "      <td>Your Job\\nIndeed is seeking an Associate Appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>NDK</td>\n",
       "      <td>Morrisville, NC 27560•Remote</td>\n",
       "      <td>https://indeed.com/viewjob?jk=ed0c996377d869d3</td>\n",
       "      <td>Up to $130,000 a year</td>\n",
       "      <td>THIS IS AN ENTRY LEVEL POSITION, NO TRAINING A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Senior Software Engineer Security and Authenti...   \n",
       "1                                               None   \n",
       "2        2021745 Cyber Security Analysts $215,000.00   \n",
       "3                      Senior Cyber Security Analyst   \n",
       "4                             Cyber Security Analyst   \n",
       "5                                               None   \n",
       "6                            Cyber Security Engineer   \n",
       "7                                               None   \n",
       "8           Cyber Security and Networking Apprentice   \n",
       "9                                               None   \n",
       "\n",
       "                                      Company                      Location  \\\n",
       "0                                   MathWorks              Natick, MA 01760   \n",
       "1                                    Citizens          Greenville, RI 02828   \n",
       "2                                      B4CORP                    Reston, VA   \n",
       "3                            TherapyNotes.com                        Remote   \n",
       "4                                         NDK        Morrisville, NC•Remote   \n",
       "5                  CentralSquare Technologies             +1 locationRemote   \n",
       "6                               Softnice Inc.                        Remote   \n",
       "7                     Amazon.com Services LLC                  New York, NY   \n",
       "8  United States Navy Career Center South Bay  Redwood City, CA+2 locations   \n",
       "9                                         NDK  Morrisville, NC 27560•Remote   \n",
       "\n",
       "                                            Links                     Salary  \\\n",
       "0  https://indeed.com/viewjob?jk=dedaae73a1bb2555                       None   \n",
       "1  https://indeed.com/viewjob?jk=8b0ad10599f3a304                       None   \n",
       "2  https://indeed.com/viewjob?jk=407b2677aa6ccc25      Up to $215,000 a year   \n",
       "3  https://indeed.com/viewjob?jk=0dd5712bac6c57aa                       None   \n",
       "4  https://indeed.com/viewjob?jk=2d39ed3a3baf0863      Up to $130,000 a year   \n",
       "5  https://indeed.com/viewjob?jk=56f081f9afeb537e  $85,000 - $100,000 a year   \n",
       "6  https://indeed.com/viewjob?jk=8b05a98ec7ae4b42                       None   \n",
       "7  https://indeed.com/viewjob?jk=5025373d360ec8f3                       None   \n",
       "8  https://indeed.com/viewjob?jk=77b578b9c0642d23   $50,000 - $95,000 a year   \n",
       "9  https://indeed.com/viewjob?jk=ed0c996377d869d3      Up to $130,000 a year   \n",
       "\n",
       "                                         Description  \n",
       "0  We are looking for a highly motivated work-fro...  \n",
       "1  Job Description:\\nAre you looking for a new an...  \n",
       "2  US CITIZENSHIP REQUIRED FOR THIS POSITION: Yes...  \n",
       "3  Cyber Security Analyst, Incident Response, Cyb...  \n",
       "4  Information Security Engineer\\nThe Information...  \n",
       "5  This role leads initiatives in risk, product s...  \n",
       "6  Job description:\\nStrong IT skills and knowled...  \n",
       "7  Bachelor’s degree in Computer Science, Compute...  \n",
       "8  Your Job\\nIndeed is seeking an Associate Appli...  \n",
       "9  THIS IS AN ENTRY LEVEL POSITION, NO TRAINING A...  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with title as index and description as an attribute\n",
    "title, description = df['Title'].to_list(), df['Description'].to_list()\n",
    "indeed_df = pd.DataFrame(data={\"Title\": title,\n",
    "                               \"Description\": description} \n",
    "                         )\n",
    "# removing rows with 'None' for their Job-Title\n",
    "indeed_df = indeed_df[indeed_df.index != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Software Engineer Security and Authenti...</td>\n",
       "      <td>We are looking for a highly motivated work-fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Job Description:\\nAre you looking for a new an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021745 Cyber Security Analysts $215,000.00</td>\n",
       "      <td>US CITIZENSHIP REQUIRED FOR THIS POSITION: Yes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Cyber Security Analyst</td>\n",
       "      <td>Cyber Security Analyst, Incident Response, Cyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyber Security Analyst</td>\n",
       "      <td>Information Security Engineer\\nThe Information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>This role leads initiatives in risk, product s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cyber Security Engineer</td>\n",
       "      <td>Job description:\\nStrong IT skills and knowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>Bachelor’s degree in Computer Science, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cyber Security and Networking Apprentice</td>\n",
       "      <td>Your Job\\nIndeed is seeking an Associate Appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>THIS IS AN ENTRY LEVEL POSITION, NO TRAINING A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Senior Software Engineer Security and Authenti...   \n",
       "1                                               None   \n",
       "2        2021745 Cyber Security Analysts $215,000.00   \n",
       "3                      Senior Cyber Security Analyst   \n",
       "4                             Cyber Security Analyst   \n",
       "5                                               None   \n",
       "6                            Cyber Security Engineer   \n",
       "7                                               None   \n",
       "8           Cyber Security and Networking Apprentice   \n",
       "9                                               None   \n",
       "\n",
       "                                         Description  \n",
       "0  We are looking for a highly motivated work-fro...  \n",
       "1  Job Description:\\nAre you looking for a new an...  \n",
       "2  US CITIZENSHIP REQUIRED FOR THIS POSITION: Yes...  \n",
       "3  Cyber Security Analyst, Incident Response, Cyb...  \n",
       "4  Information Security Engineer\\nThe Information...  \n",
       "5  This role leads initiatives in risk, product s...  \n",
       "6  Job description:\\nStrong IT skills and knowled...  \n",
       "7  Bachelor’s degree in Computer Science, Compute...  \n",
       "8  Your Job\\nIndeed is seeking an Associate Appli...  \n",
       "9  THIS IS AN ENTRY LEVEL POSITION, NO TRAINING A...  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the above dataframe into dictionary for iteration {title: description}\n",
    "indeed = {}\n",
    "for (t, d) in zip(title, description): # loops through the list title and description\n",
    "    indeed[t] = d # sets the title as key and the description as the value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance uncomment below to see how to access each description using the title:\n",
    "\n",
    "# indeed ['Senior Software Engineer Security and Authentication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through the Job's to tokenize into sentences and words\n",
    "for key in indeed:\n",
    "    text = indeed[key]\n",
    "    # Tokenize into sentence or phrase\n",
    "    sentence_count, s1 = get_sentence_counter(text=text)\n",
    "    indeed_sentence = make_df(sentence_count.most_common()[:-n-1:-1], s1,\n",
    "            ind_name= f'Least Occuring Sentences in\\n \\'{key}\\'')\n",
    "    # Tokenize into words\n",
    "    word_count, s2 = get_text_counter(text, avoid, word_pattern)\n",
    "    indeed_word = make_df(word_count.most_common()[:-n-1:-1], s2,\n",
    "            ind_name= f'Least Occuring Words in\\n \\'{key}\\'')\n",
    "    break\n",
    "# I am breaking here because I would like to see what could be done for just one job posting-\n",
    "# then find a way to save each iteration for each job posting separately in  some format.\n",
    "# For now, I am just saving the sentence/phrase and word tokens and their freqz into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Least Occuring Sentences in\n",
       " 'Senior Software Engineer Security and Authentication'</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Our sales staff provides knowledgeable consultative solutions leveraging a strong local and national marketing</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and then adds its own security compliance managed security and professional services nationally</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s leading security product manufacturers</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\neSecurity Solutions leverages its relationship with the industry</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paced environment and have achieved very high growth in the hot IT security industry</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We are a team of overachievers who thrive in a fast</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The ability to move and grow with our company is definitely a benefit of working at eSecurity Solutions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\nThis is a challenging and rewarding sales opportunity with an opportunity to really make an impact</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You will inherit multiple current customer accounts to build on for your territory</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This sales position is a work from home position with a national territory</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>managed security services and complementary security products</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\nResponsibilities will include selling security solutions comprised of high margin professional</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>managed security services and product sales to small business customers and prospects</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Your mission will be to grow our services</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home solutions sales professional to drive continued high growth in our successful Cyber security small business sales</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We are looking for a highly motivated work</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 year</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.034091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.034091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Absolute frequency  \\\n",
       "Least Occuring Sentences in\\n 'Senior Software ...                       \n",
       " Our sales staff provides knowledgeable consult...                 1.0   \n",
       " and then adds its own security compliance mana...                 1.0   \n",
       "s leading security product manufacturers                           1.0   \n",
       "\\neSecurity Solutions leverages its relationshi...                 1.0   \n",
       "paced environment and have achieved very high g...                 1.0   \n",
       " We are a team of overachievers who thrive in a...                 1.0   \n",
       " The ability to move and grow with our company ...                 1.0   \n",
       "\\nThis is a challenging and rewarding sales opp...                 1.0   \n",
       " You will inherit multiple current customer acc...                 1.0   \n",
       " This sales position is a work from home positi...                 1.0   \n",
       " managed security services and complementary se...                 1.0   \n",
       "\\nResponsibilities will include selling securit...                 1.0   \n",
       " managed security services and product sales to...                 1.0   \n",
       " Your mission will be to grow our services                         1.0   \n",
       "home solutions sales professional to drive cont...                 1.0   \n",
       "from                                                               1.0   \n",
       "We are looking for a highly motivated work                         1.0   \n",
       " 1 year                                                            2.0   \n",
       "Required                                                           3.0   \n",
       "                                                                   3.0   \n",
       "\n",
       "                                                    Relative frequency  \n",
       "Least Occuring Sentences in\\n 'Senior Software ...                      \n",
       " Our sales staff provides knowledgeable consult...            0.011364  \n",
       " and then adds its own security compliance mana...            0.011364  \n",
       "s leading security product manufacturers                      0.011364  \n",
       "\\neSecurity Solutions leverages its relationshi...            0.011364  \n",
       "paced environment and have achieved very high g...            0.011364  \n",
       " We are a team of overachievers who thrive in a...            0.011364  \n",
       " The ability to move and grow with our company ...            0.011364  \n",
       "\\nThis is a challenging and rewarding sales opp...            0.011364  \n",
       " You will inherit multiple current customer acc...            0.011364  \n",
       " This sales position is a work from home positi...            0.011364  \n",
       " managed security services and complementary se...            0.011364  \n",
       "\\nResponsibilities will include selling securit...            0.011364  \n",
       " managed security services and product sales to...            0.011364  \n",
       " Your mission will be to grow our services                    0.011364  \n",
       "home solutions sales professional to drive cont...            0.011364  \n",
       "from                                                          0.011364  \n",
       "We are looking for a highly motivated work                    0.011364  \n",
       " 1 year                                                       0.022727  \n",
       "Required                                                      0.034091  \n",
       "                                                              0.034091  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_sentence.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Least Occuring Words in\n",
       " 'Senior Software Engineer Security and Authentication'</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fully</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preferred</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bachelor</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employees</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>considerations</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commission</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supplemental</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friday</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monday</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dental</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Absolute frequency  \\\n",
       "Least Occuring Words in\\n 'Senior Software Engi...                       \n",
       "fully                                                              1.0   \n",
       "availability                                                       1.0   \n",
       "preferred                                                          1.0   \n",
       "b2b                                                                1.0   \n",
       "bachelor                                                           1.0   \n",
       "education                                                          1.0   \n",
       "employees                                                          1.0   \n",
       "all                                                                1.0   \n",
       "considerations                                                     1.0   \n",
       "covid                                                              1.0   \n",
       "commission                                                         1.0   \n",
       "supplemental                                                       1.0   \n",
       "friday                                                             1.0   \n",
       "monday                                                             1.0   \n",
       "schedule                                                           1.0   \n",
       "vision                                                             1.0   \n",
       "off                                                                1.0   \n",
       "paid                                                               1.0   \n",
       "health                                                             1.0   \n",
       "dental                                                             1.0   \n",
       "\n",
       "                                                    Relative frequency  \n",
       "Least Occuring Words in\\n 'Senior Software Engi...                      \n",
       "fully                                                         0.002105  \n",
       "availability                                                  0.002105  \n",
       "preferred                                                     0.002105  \n",
       "b2b                                                           0.002105  \n",
       "bachelor                                                      0.002105  \n",
       "education                                                     0.002105  \n",
       "employees                                                     0.002105  \n",
       "all                                                           0.002105  \n",
       "considerations                                                0.002105  \n",
       "covid                                                         0.002105  \n",
       "commission                                                    0.002105  \n",
       "supplemental                                                  0.002105  \n",
       "friday                                                        0.002105  \n",
       "monday                                                        0.002105  \n",
       "schedule                                                      0.002105  \n",
       "vision                                                        0.002105  \n",
       "off                                                           0.002105  \n",
       "paid                                                          0.002105  \n",
       "health                                                        0.002105  \n",
       "dental                                                        0.002105  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_word.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
